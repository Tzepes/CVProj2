{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "06f15e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0847c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_out_folder(file_name):\n",
    "    \"\"\"\n",
    "    Get the output folder path based on the input file name.\n",
    "    \"\"\"\n",
    "    # Extract the number\n",
    "    match = re.match(r\"(\\d+)_\", file_name)\n",
    "    if match:\n",
    "        number = int(match.group(1))\n",
    "    else:\n",
    "        number = \"unknown\"\n",
    "\n",
    "    # Check for 'query' or 'reference'\n",
    "    if \"query\" in file_name:\n",
    "        subfolder = \"query\"\n",
    "    elif \"reference\" in file_name:\n",
    "        subfolder = \"reference\"\n",
    "    else:\n",
    "        subfolder = \"other\"\n",
    "\n",
    "    output_folder = os.path.join(\"frames\", subfolder, f\"vid_{number}\")\n",
    "    return output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "92bfb1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, output_folder, target_fps=15, max_pixels=120000):\n",
    "    \"\"\"\n",
    "    Extract frames at target_fps and resize so each saved frame has <= max_pixels.\n",
    "    Creates (or loads) a mapping JSON with:\n",
    "      - orig_fps:    original capture FPS\n",
    "      - frame_step:  sampling step\n",
    "      - orig_indices: list of original frame numbers for each saved frame\n",
    "    \"\"\"\n",
    "    mapping_path = os.path.join(output_folder, \"frame_mapping.json\")\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # If mapping already exists, load and return it\n",
    "    if os.path.isfile(mapping_path):\n",
    "        with open(mapping_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        return data[\"orig_fps\"], data[\"frame_step\"], data[\"orig_indices\"]\n",
    "\n",
    "    # Otherwise extract frames and build mapping\n",
    "    cap = cv.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(f\"Cannot open video {video_path}\")\n",
    "    orig_fps   = cap.get(cv.CAP_PROP_FPS) or target_fps\n",
    "    frame_step = max(int(round(orig_fps / target_fps)), 1)\n",
    "\n",
    "    orig_indices = []\n",
    "    count = 0   # original frame index\n",
    "    saved = 0   # downsampled frame index\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if count % frame_step == 0:\n",
    "            # resize to <= max_pixels\n",
    "            h, w = frame.shape[:2]\n",
    "            scale = (max_pixels / float(w * h)) ** 0.5\n",
    "            if scale < 1.0:\n",
    "                frame = cv.resize(\n",
    "                    frame,\n",
    "                    (int(w*scale), int(h*scale)),\n",
    "                    interpolation=cv.INTER_AREA\n",
    "                )\n",
    "            # save frame\n",
    "            frame_filename = os.path.join(output_folder, f\"frame_{saved:04d}.jpg\")\n",
    "            cv.imwrite(frame_filename, frame)\n",
    "            orig_indices.append(count)\n",
    "            saved += 1\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Save the mapping JSON\n",
    "    with open(mapping_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"orig_fps\":    orig_fps,\n",
    "            \"frame_step\":  frame_step,\n",
    "            \"orig_indices\": orig_indices\n",
    "        }, f)\n",
    "\n",
    "    return orig_fps, frame_step, orig_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b2031da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_query_to_reference(video_file, pca_model=None, target_fps=15, max_pixels=120000):\n",
    "    \"\"\"\n",
    "    Match query frames to reference frames using PCA for dimensionality reduction.\n",
    "    Args:\n",
    "        video_file (str): Path to the input video file.\n",
    "        pca_model (PCA, optional): Pre-trained PCA model. If None, a new model will be created.\n",
    "        pca_dim (int): Number of dimensions for PCA.\n",
    "        lambda_val (float): Regularization parameter for PCA.\n",
    "        fps (int): Frames per second for the video.\n",
    "    Returns:\n",
    "        tuple: Output folder path and PCA model.\n",
    "    \"\"\"\n",
    "    # Determine folders and extract frames if needed\n",
    "    print(f\"Processing video file: {video_file}...\")\n",
    "    out_folder = get_out_folder(os.path.basename(video_file))\n",
    "    orig_fps, frame_step, orig_indices = extract_frames(video_file, out_folder, target_fps, max_pixels)\n",
    "    return out_folder, pca_model, orig_fps, frame_step, orig_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a2445f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def load_frame_descriptors(frame_folder, sift, pca_model=None, pca_dim=64, fit_pca=False):\n",
    "    # Could multithread\n",
    "    \n",
    "    \"\"\"\n",
    "    Load frames from folder, extract SIFT descriptors per frame, apply PCA, return frame-level vectors.\n",
    "    If fit_pca=True, stack all keypoint descs for PCA fit; else apply existing pca_model.\n",
    "    \"\"\"\n",
    "    # Gather frame paths\n",
    "    frame_paths = sorted(glob.glob(os.path.join(frame_folder, \"frame_*.jpg\")))\n",
    "    all_descs = []\n",
    "    key_descs = []\n",
    "\n",
    "    # First pass: collect for PCA if needed\n",
    "    # if fit_pca:\n",
    "    for fp in tqdm(frame_paths, desc=\"Collecting descriptors for PCA\"):\n",
    "        img = cv.imread(fp, cv.IMREAD_GRAYSCALE)\n",
    "        _, des = sift.detectAndCompute(img, None)\n",
    "        if des is not None:\n",
    "            key_descs.append(des)\n",
    "    stacked = np.vstack(key_descs)\n",
    "    pca_model = PCA(n_components=pca_dim, whiten=True, svd_solver='auto')\n",
    "    pca_model.fit(stacked)\n",
    "    \n",
    "    print(f\"Fitted PCA model with {pca_dim} dimensions.\")\n",
    "    print(f\"Explained variance ratio: {pca_model.explained_variance_ratio_}\")\n",
    "    print(f\"Total variance explained: {np.sum(pca_model.explained_variance_ratio_)}\")\n",
    "    print(f\"Number of components: {pca_model.n_components_}\")\n",
    "\n",
    "    # Second pass: extract per-frame vector\n",
    "    for fp in tqdm(frame_paths, desc=\"Extracting frame vectors\"):\n",
    "        img = cv.imread(fp, cv.IMREAD_GRAYSCALE)\n",
    "        _, des = sift.detectAndCompute(img, None)\n",
    "        if des is not None and pca_model is not None:\n",
    "            des_pca = pca_model.transform(des)\n",
    "            frame_vec = np.mean(des_pca, axis=0)\n",
    "        else:\n",
    "            frame_vec = np.zeros(pca_dim, dtype=np.float32)\n",
    "        all_descs.append(frame_vec)\n",
    "        \n",
    "    print(f\"Extracted {len(all_descs)} frame vectors from {len(frame_paths)} frames.\")\n",
    "    print(f\"Shape of each frame vector: {all_descs[0].shape if all_descs else 'N/A'}\")\n",
    "    print(f\"Total number of frames processed: {len(all_descs)}\")\n",
    "    print(f\"Shape of all descriptors: {np.array(all_descs).shape}\")\n",
    "    print(f\"Shape of PCA model components: {pca_model.components_.shape if pca_model else 'N/A'}\")\n",
    "    return np.vstack(all_descs), pca_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "06446a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cte_correlation(query_desc, ref_desc, lambda_val=1e-3):\n",
    "    Tq, D = query_desc.shape\n",
    "    Tr, _ = ref_desc.shape\n",
    "    N = 1 << int(np.ceil(np.log2(max(Tq, Tr))))\n",
    "    Q = np.zeros((N, D), dtype=np.float32)\n",
    "    R = np.zeros((N, D), dtype=np.float32)\n",
    "    Q[:Tq] = query_desc; R[:Tr] = ref_desc\n",
    "    Qf = np.fft.rfft(Q, n=N, axis=0)\n",
    "    Rf = np.fft.rfft(R, n=N, axis=0)\n",
    "    num = np.sum(np.conj(Qf) * Rf, axis=1)\n",
    "    den = np.sum(np.abs(Qf) ** 2, axis=1)\n",
    "    scores = np.fft.irfft(num / (den + lambda_val), n=N)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "488c2389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_offset(scores, fps=15):\n",
    "    best_frame = int(np.argmax(scores))\n",
    "    print(f\"Best frame offset: {best_frame} (at {best_frame / fps:.4f} seconds)\")\n",
    "    return best_frame, best_frame / fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e80b361b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video pair 01: train/task1/01_query.mp4 (query) and train/task1/01_reference.mp4 (reference)\n",
      "Processing video file: train/task1/01_query.mp4...\n",
      "first time fitting PCA on query frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting descriptors for PCA: 100%|██████████| 60/60 [00:03<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted PCA model with 64 dimensions.\n",
      "Explained variance ratio: [0.12943125 0.07260717 0.04968274 0.04381259 0.03843722 0.03686541\n",
      " 0.03447191 0.03251746 0.03159618 0.02473073 0.0206832  0.02050975\n",
      " 0.01949956 0.01876873 0.01774731 0.01685929 0.01583739 0.01538047\n",
      " 0.01467589 0.01320246 0.01283477 0.01241744 0.01147002 0.01094152\n",
      " 0.01028205 0.00973011 0.00937545 0.00915288 0.00823307 0.00716604\n",
      " 0.00703366 0.00692178 0.00680079 0.00664198 0.00659646 0.00629149\n",
      " 0.00590707 0.00566627 0.00549446 0.00543285 0.00535972 0.00509093\n",
      " 0.00476356 0.00472138 0.00445179 0.00437367 0.0042983  0.00420794\n",
      " 0.004095   0.00400351 0.00388165 0.0037839  0.00374683 0.00370276\n",
      " 0.00338279 0.00333504 0.00321187 0.00315278 0.00308111 0.00283374\n",
      " 0.00281845 0.00274101 0.00258864 0.00250044]\n",
      "Total variance explained: 0.9218336939811707\n",
      "Number of components: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting frame vectors: 100%|██████████| 60/60 [00:03<00:00, 16.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 60 frame vectors from 60 frames.\n",
      "Shape of each frame vector: (64,)\n",
      "Total number of frames processed: 60\n",
      "Shape of all descriptors: (60, 64)\n",
      "Shape of PCA model components: (64, 128)\n",
      "Processing video file: train/task1/01_reference.mp4...\n",
      "Extracting reference frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting descriptors for PCA: 100%|██████████| 600/600 [00:35<00:00, 16.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted PCA model with 64 dimensions.\n",
      "Explained variance ratio: [0.12195007 0.07196461 0.04983318 0.04736897 0.04001319 0.03796236\n",
      " 0.03645194 0.03519392 0.03283417 0.02388236 0.02276749 0.02002756\n",
      " 0.01969174 0.01895109 0.0178208  0.01646458 0.01506472 0.01474224\n",
      " 0.0141797  0.01303325 0.01269642 0.01218205 0.01105565 0.01044854\n",
      " 0.00995714 0.00984532 0.00935247 0.00904017 0.00783704 0.00739236\n",
      " 0.00724711 0.00693813 0.00661277 0.0065147  0.00612273 0.00597579\n",
      " 0.00575747 0.0055827  0.00552923 0.00536137 0.00510534 0.00509681\n",
      " 0.00485429 0.00456053 0.00448023 0.00442271 0.0043247  0.00413402\n",
      " 0.00409416 0.00400369 0.00395451 0.0039111  0.00377584 0.00369176\n",
      " 0.00348304 0.00333615 0.00319307 0.00300111 0.00287097 0.002828\n",
      " 0.00275751 0.00270829 0.00260433 0.00255512]\n",
      "Total variance explained: 0.9213943481445312\n",
      "Number of components: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting frame vectors: 100%|██████████| 600/600 [00:33<00:00, 17.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 600 frame vectors from 600 frames.\n",
      "Shape of each frame vector: (64,)\n",
      "Total number of frames processed: 600\n",
      "Shape of all descriptors: (600, 64)\n",
      "Shape of PCA model components: (64, 128)\n",
      "Pair 01: matched original frame 897 (14.95s)\n"
     ]
    }
   ],
   "source": [
    "sift = cv.SIFT_create()\n",
    "pca_model = None\n",
    "results = []\n",
    "\n",
    "videos_idx_limit = 1 # Limit to which video number we want to stop process (1 - 15)\n",
    "\n",
    "for idx in range(1, videos_idx_limit + 1):\n",
    "    idx = 1 # Set to a specific index for testing, remove this line for full loop\n",
    "    q_file = f\"train/task1/{idx:02d}_query.mp4\"\n",
    "    r_file = f\"train/task1/{idx:02d}_reference.mp4\"\n",
    "    \n",
    "    print(f\"Processing video pair {idx:02d}: {q_file} (query) and {r_file} (reference)\")\n",
    "    \n",
    "    # Process query video\n",
    "    q_folder, pca_model, q_fps, q_step, q_map = match_query_to_reference(q_file, pca_model, target_fps=20, max_pixels=180000)\n",
    "    print(\"first time fitting PCA on query frames\")\n",
    "    q_desc, pca_model = load_frame_descriptors(q_folder, sift, pca_model, pca_dim=64, fit_pca=(pca_model is None))\n",
    "    \n",
    "    # Process reference video\n",
    "    r_folder, _, r_fps, r_step, r_map = match_query_to_reference(r_file, pca_model, target_fps=20, max_pixels=180000)\n",
    "    print(\"Extracting reference frames\")\n",
    "    r_desc, _ = load_frame_descriptors(r_folder, sift, pca_model, pca_dim=64, fit_pca=False)\n",
    "    \n",
    "    \n",
    "    scores = compute_cte_correlation(q_desc, r_desc, lambda_val=1e-3)\n",
    "    \n",
    "    # Find best *downsampled* frame delta\n",
    "    N     = scores.shape[0]\n",
    "    delta = int(np.argmax(scores))\n",
    "    if delta > N//2:\n",
    "        delta -= N\n",
    "\n",
    "    # Map back to original reference frame\n",
    "    delta = max(delta, 0)            # clamp if you only allow forward shifts\n",
    "    orig_frame = r_map[delta]        # true original-frame index\n",
    "    orig_time  = orig_frame / r_fps  # in seconds\n",
    "\n",
    "    print(f\"Pair {idx:02d}: matched original frame {orig_frame} \"\n",
    "        f\"({orig_time:.2f}s)\")\n",
    "    results.append((idx, orig_frame, orig_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7d9501c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # —— Insert this block right here ——\n",
    "# N = scores.shape[0]\n",
    "# delta = int(np.argmax(scores))\n",
    "# # wrap‐around correction\n",
    "# if delta > N // 2:\n",
    "#     delta = delta - N\n",
    "\n",
    "# # map back to the original video’s frame rate\n",
    "# # these must match how you extracted frames:\n",
    "# #   orig_fps  = cap.get(cv2.CAP_PROP_FPS)    (e.g. 30)\n",
    "# #   target_fps = 15\n",
    "# #   frame_step = round(orig_fps/target_fps)  (e.g. 2)\n",
    "# orig_frame = delta * frame_step\n",
    "# orig_time  = orig_frame / orig_fps\n",
    "# # —— end insertion ——  \n",
    "\n",
    "# print(f\"Pair {idx:02d}: match at normalized frame {delta},\"\n",
    "#       f\" original frame {orig_frame}, time {orig_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "70d9b13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   pair |   best_frame |   best_time_s |\n",
      "|-------:|-------------:|--------------:|\n",
      "|      1 |          897 |         14.95 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Suppose `results` is your list of (pair, best_frame, best_time_s)\n",
    "# from the matching loop:\n",
    "\n",
    "# Example:\n",
    "# results = [\n",
    "#     (1, 45, 3.00),\n",
    "#     (2, 92, 6.13),\n",
    "#     # ...\n",
    "# ]\n",
    "\n",
    "df = pd.DataFrame(results, columns=[\"pair\", \"best_frame\", \"best_time_s\"])\n",
    "print(df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "92132c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = [\n",
    "#     (1, 422, 14.0667),\n",
    "#     (2, 625, 20.8333),\n",
    "#     (3, 274, 9.13333),\n",
    "#     (4, 418, 13.9333),\n",
    "#     (5, 186, 6.2),\n",
    "#     (6, 618, 20.6),\n",
    "#     (7, 978, 32.6),\n",
    "#     (8, 472, 15.7333),\n",
    "#     (9, 649, 21.6333),\n",
    "#     (10, 804, 26.8),\n",
    "#     (11, 252, 8.4),\n",
    "#     (12, 77, 2.56667),\n",
    "#     (13, 448, 14.9333),\n",
    "#     (14, 778, 25.9333),\n",
    "#     (15, 223, 7.43333)\n",
    "# ]\n",
    "# df = pd.DataFrame(results, columns=[\"pair\", \"best_frame\", \"best_time_s\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ebcf4b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = [\n",
    "    585,\n",
    "    # 756,\n",
    "    # 650,\n",
    "    # 360,\n",
    "    # 340,\n",
    "    # 560,\n",
    "    # 590,\n",
    "    # 1497,\n",
    "    # 1196,\n",
    "    # 1160,\n",
    "    # 1120,\n",
    "    # 450,\n",
    "    # 636,\n",
    "    # 610,\n",
    "    # 1250\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b2282d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth differences: [312]\n",
      "Accuracy: 0.00% (±60 frames tolerance)\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean([abs(gt - bf) <= 60 for gt, (_, bf, _) in zip(ground_truth, results)])\n",
    "difference = [abs(gt - bf) for gt, (_, bf, _) in zip(ground_truth, results)]\n",
    "print(f\"Ground truth differences: {difference}\")\n",
    "print(f\"Accuracy: {accuracy:.2%} (±60 frames tolerance)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
