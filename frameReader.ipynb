{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "06f15e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0847c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_out_folder(file_name):\n",
    "    \"\"\"\n",
    "    Get the output folder path based on the input file name.\n",
    "    \"\"\"\n",
    "    # Extract the number\n",
    "    match = re.match(r\"(\\d+)_\", file_name)\n",
    "    if match:\n",
    "        number = int(match.group(1))\n",
    "    else:\n",
    "        number = \"unknown\"\n",
    "\n",
    "    # Check for 'query' or 'reference'\n",
    "    if \"query\" in file_name:\n",
    "        subfolder = \"query\"\n",
    "    elif \"reference\" in file_name:\n",
    "        subfolder = \"reference\"\n",
    "    else:\n",
    "        subfolder = \"other\"\n",
    "\n",
    "    output_folder = os.path.join(\"frames\", subfolder, f\"vid_{number}\")\n",
    "    return output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "92bfb1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, output_folder, target_fps=15, max_pixels=120000):\n",
    "    \"\"\"\n",
    "    Extract frames from a video and save them to the specified output folder.\n",
    "    Args:\n",
    "        video_path (str): Path to the input video file.\n",
    "        output_folder (str): Path to the folder where frames will be saved.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        cap = cv.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise IOError(f\"Cannot open video {video_path}\")\n",
    "        orig_fps = cap.get(cv.CAP_PROP_FPS) or target_fps\n",
    "        frame_step = max(int(round(orig_fps / target_fps)), 1)\n",
    "\n",
    "        count = 0\n",
    "        saved = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if count % frame_step == 0:\n",
    "                # Resize to max_pixels\n",
    "                h, w = frame.shape[:2]\n",
    "                scale = (max_pixels / float(w * h)) ** 0.5\n",
    "                if scale < 1.0:\n",
    "                    frame = cv.resize(frame, (int(w * scale), int(h * scale)), interpolation=cv.INTER_AREA)\n",
    "                # Save frame\n",
    "                cv.imwrite(os.path.join(output_folder, f\"frame_{saved:04d}.jpg\"), frame)\n",
    "                saved += 1\n",
    "            count += 1\n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b2031da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_query_to_reference(video_file, pca_model=None, target_fps=15, max_pixels=120000):\n",
    "    \"\"\"\n",
    "    Match query frames to reference frames using PCA for dimensionality reduction.\n",
    "    Args:\n",
    "        video_file (str): Path to the input video file.\n",
    "        pca_model (PCA, optional): Pre-trained PCA model. If None, a new model will be created.\n",
    "        pca_dim (int): Number of dimensions for PCA.\n",
    "        lambda_val (float): Regularization parameter for PCA.\n",
    "        fps (int): Frames per second for the video.\n",
    "    Returns:\n",
    "        tuple: Output folder path and PCA model.\n",
    "    \"\"\"\n",
    "    # Determine folders and extract frames if needed\n",
    "    print(f\"Processing video file: {video_file}...\")\n",
    "    out_folder = get_out_folder(os.path.basename(video_file))\n",
    "    extract_frames(video_file, out_folder, target_fps, max_pixels)\n",
    "    return out_folder, pca_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a2445f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def load_frame_descriptors(frame_folder, sift, pca_model=None, pca_dim=64, fit_pca=False):\n",
    "    # Could multithread\n",
    "    \n",
    "    \"\"\"\n",
    "    Load frames from folder, extract SIFT descriptors per frame, apply PCA, return frame-level vectors.\n",
    "    If fit_pca=True, stack all keypoint descs for PCA fit; else apply existing pca_model.\n",
    "    \"\"\"\n",
    "    # Gather frame paths\n",
    "    frame_paths = sorted(glob.glob(os.path.join(frame_folder, \"frame_*.jpg\")))\n",
    "    all_descs = []\n",
    "    key_descs = []\n",
    "\n",
    "    # First pass: collect for PCA if needed\n",
    "    if fit_pca:\n",
    "        for fp in tqdm(frame_paths, desc=\"Collecting descriptors for PCA\"):\n",
    "            img = cv.imread(fp, cv.IMREAD_GRAYSCALE)\n",
    "            _, des = sift.detectAndCompute(img, None)\n",
    "            if des is not None:\n",
    "                key_descs.append(des)\n",
    "        stacked = np.vstack(key_descs)\n",
    "        pca_model = PCA(n_components=pca_dim, whiten=True, svd_solver='auto')\n",
    "        pca_model.fit(stacked)\n",
    "        \n",
    "        print(f\"Fitted PCA model with {pca_dim} dimensions.\")\n",
    "        print(f\"Explained variance ratio: {pca_model.explained_variance_ratio_}\")\n",
    "        print(f\"Total variance explained: {np.sum(pca_model.explained_variance_ratio_)}\")\n",
    "        print(f\"Number of components: {pca_model.n_components_}\")\n",
    "\n",
    "    # Second pass: extract per-frame vector\n",
    "    for fp in tqdm(frame_paths, desc=\"Extracting frame vectors\"):\n",
    "        img = cv.imread(fp, cv.IMREAD_GRAYSCALE)\n",
    "        _, des = sift.detectAndCompute(img, None)\n",
    "        if des is not None and pca_model is not None:\n",
    "            des_pca = pca_model.transform(des)\n",
    "            frame_vec = np.mean(des_pca, axis=0)\n",
    "        else:\n",
    "            frame_vec = np.zeros(pca_dim, dtype=np.float32)\n",
    "        all_descs.append(frame_vec)\n",
    "        \n",
    "    print(f\"Extracted {len(all_descs)} frame vectors from {len(frame_paths)} frames.\")\n",
    "    print(f\"Shape of each frame vector: {all_descs[0].shape if all_descs else 'N/A'}\")\n",
    "    print(f\"Total number of frames processed: {len(all_descs)}\")\n",
    "    print(f\"Shape of all descriptors: {np.array(all_descs).shape}\")\n",
    "    print(f\"Shape of PCA model components: {pca_model.components_.shape if pca_model else 'N/A'}\")\n",
    "    return np.vstack(all_descs), pca_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "06446a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cte_correlation(query_desc, ref_desc, lambda_val=1e-3):\n",
    "    Tq, D = query_desc.shape\n",
    "    Tr, _ = ref_desc.shape\n",
    "    N = 1 << int(np.ceil(np.log2(max(Tq, Tr))))\n",
    "    Q = np.zeros((N, D), dtype=np.float32)\n",
    "    R = np.zeros((N, D), dtype=np.float32)\n",
    "    Q[:Tq] = query_desc; R[:Tr] = ref_desc\n",
    "    Qf = np.fft.rfft(Q, n=N, axis=0)\n",
    "    Rf = np.fft.rfft(R, n=N, axis=0)\n",
    "    num = np.sum(np.conj(Qf) * Rf, axis=1)\n",
    "    den = np.sum(np.abs(Qf) ** 2, axis=1)\n",
    "    scores = np.fft.irfft(num / (den + lambda_val), n=N)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "488c2389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_offset(scores, fps=15):\n",
    "    best_frame = int(np.argmax(scores))\n",
    "    return best_frame, best_frame / fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e80b361b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video pair 01: train/task1/01_query.mp4 (query) and train/task1/01_reference.mp4 (reference)\n",
      "Processing video file: train/task1/01_query.mp4...\n",
      "first time fitting PCA on query frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting descriptors for PCA: 100%|██████████| 45/45 [00:01<00:00, 26.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted PCA model with 64 dimensions.\n",
      "Explained variance ratio: [0.13364685 0.07236713 0.04777729 0.04365035 0.03892459 0.03587165\n",
      " 0.0324444  0.03233577 0.03105574 0.02435083 0.02179296 0.0212551\n",
      " 0.01936354 0.01897359 0.01732421 0.01696339 0.01562415 0.01480238\n",
      " 0.01422864 0.01338267 0.01279366 0.01235731 0.01181194 0.0112356\n",
      " 0.01041393 0.01005563 0.00940045 0.00902721 0.0077481  0.00745637\n",
      " 0.00718191 0.00689055 0.00681362 0.00675104 0.00654068 0.00627357\n",
      " 0.00609372 0.00577214 0.00570838 0.0054328  0.00534008 0.00507193\n",
      " 0.00480839 0.00475587 0.00456237 0.00455519 0.00441729 0.0042141\n",
      " 0.00411499 0.00393376 0.00382679 0.00374506 0.00368525 0.00360587\n",
      " 0.00351729 0.0033998  0.00320866 0.00314879 0.00296239 0.00287407\n",
      " 0.00279593 0.00270998 0.00266765 0.00261746]\n",
      "Total variance explained: 0.9224327802658081\n",
      "Number of components: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting frame vectors: 100%|██████████| 45/45 [00:02<00:00, 22.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 45 frame vectors from 45 frames.\n",
      "Shape of each frame vector: (64,)\n",
      "Total number of frames processed: 45\n",
      "Shape of all descriptors: (45, 64)\n",
      "Shape of PCA model components: (64, 128)\n",
      "Processing video file: train/task1/01_reference.mp4...\n",
      "Extracting reference frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting frame vectors: 100%|██████████| 450/450 [00:17<00:00, 25.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 450 frame vectors from 450 frames.\n",
      "Shape of each frame vector: (64,)\n",
      "Total number of frames processed: 450\n",
      "Shape of all descriptors: (450, 64)\n",
      "Shape of PCA model components: (64, 128)\n",
      "Computed CTE correlation scores with shape: (512,)\n",
      "Scores: [-0.39294919 -0.3646284  -0.39549076 -0.40652204 -0.3671819  -0.38240468\n",
      " -0.39858979 -0.37130247 -0.34073845 -0.40034822]\n",
      "Pair 01: offset 322 frames (10.73s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sift = cv.SIFT_create()\n",
    "pca_model = None\n",
    "results = []\n",
    "\n",
    "videos_idx_limit = 1 # Limit to which video number we want to stop process (1 - 15)\n",
    "\n",
    "for idx in range(1, videos_idx_limit + 1):\n",
    "    q_file = f\"train/task1/{idx:02d}_query.mp4\"\n",
    "    r_file = f\"train/task1/{idx:02d}_reference.mp4\"\n",
    "    \n",
    "    print(f\"Processing video pair {idx:02d}: {q_file} (query) and {r_file} (reference)\")\n",
    "    \n",
    "    # Process query video\n",
    "    q_folder, pca_model = match_query_to_reference(q_file, pca_model, target_fps=25, max_pixels=180000)\n",
    "    print(\"first time fitting PCA on query frames\")\n",
    "    q_desc, pca_model = load_frame_descriptors(q_folder, sift, pca_model, pca_dim=64, fit_pca=(pca_model is None))\n",
    "    \n",
    "    # Process reference video\n",
    "    r_folder, _ = match_query_to_reference(r_file, pca_model, target_fps=25, max_pixels=180000)\n",
    "    print(\"Extracting reference frames\")\n",
    "    r_desc, _ = load_frame_descriptors(r_folder, sift, pca_model, pca_dim=64, fit_pca=False)\n",
    "    \n",
    "    \n",
    "    scores = compute_cte_correlation(q_desc, r_desc, lambda_val=1e-3)\n",
    "    print(f\"Computed CTE correlation scores with shape: {scores.shape}\")\n",
    "    print(f\"Scores: {scores[:10]}\")  # Print first 10 scores for verification\n",
    "    best_frame, best_time = find_best_offset(scores, fps=30)\n",
    "    results.append((idx, best_frame, best_time))\n",
    "    print(f\"Pair {idx:02d}: offset {best_frame} frames ({best_time:.2f}s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "70d9b13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   pair |   best_frame |   best_time_s |\n",
      "|-------:|-------------:|--------------:|\n",
      "|      1 |          322 |       10.7333 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Suppose `results` is your list of (pair, best_frame, best_time_s)\n",
    "# from the matching loop:\n",
    "\n",
    "# Example:\n",
    "# results = [\n",
    "#     (1, 45, 3.00),\n",
    "#     (2, 92, 6.13),\n",
    "#     # ...\n",
    "# ]\n",
    "\n",
    "df = pd.DataFrame(results, columns=[\"pair\", \"best_frame\", \"best_time_s\"])\n",
    "print(df.to_markdown(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
